{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Environment Test & Setup Validation - Escape Cage RL Project\n",
        "\n",
        "This notebook provides comprehensive testing and validation of the environment setup for the Escape Cage Reinforcement Learning project.\n",
        "\n",
        "## What This Notebook Tests:\n",
        "\n",
        "1. **Core Dependencies**: TensorFlow, Keras, NumPy, and other essential libraries\n",
        "2. **RL Framework**: Gymnasium and Stable-Baselines3 functionality\n",
        "3. **Neural Network**: Basic model creation and training\n",
        "4. **Performance**: Quick benchmarks to ensure everything runs smoothly\n",
        "\n",
        "## Success Criteria:\n",
        "\n",
        "- All imports succeed without errors\n",
        "- Neural network can be created and trained\n",
        "- RL environment can be instantiated and run\n",
        "- Basic training loop completes successfully\n",
        "\n",
        "## Getting Started:\n",
        "\n",
        "Run all cells in order. If any cell fails, check the error message and ensure all dependencies are properly installed.\n",
        "\n",
        "**Expected Runtime**: ~2-3 minutes for complete validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports successful!\n",
            "TensorFlow version: 2.19.0\n",
            "Keras version: 3.10.0\n",
            "NumPy version: 2.1.3\n"
          ]
        }
      ],
      "source": [
        "# Core ML and Deep Learning Libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "\n",
        "# Reinforcement Learning Libraries  \n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# Utilities and Tools\n",
        "import yaml\n",
        "from PIL import Image\n",
        "import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Visualization Setup\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)  # For reproducible results\n",
        "\n",
        "print(\"All imports successful!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Python version: {sys.version.split()[0]}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Gymnasium version: {gym.__version__}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check GPU availability\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU acceleration available!\")\n",
        "    print(f\"   GPUs detected: {len(tf.config.list_physical_devices('GPU'))}\")\n",
        "else:\n",
        "    print(\"Running on CPU (this is fine for our project)\")\n",
        "    \n",
        "print(\"\\nEnvironment validation starting...\")  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ§  Testing TensorFlow/Keras...\n",
            "âœ… Neural network created with 2817 parameters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/romacarapetean/Desktop/NEW-IDEA-main/escape_cage_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TensorFlow/Keras training test successful!\n"
          ]
        }
      ],
      "source": [
        "# Testing TensorFlow/Keras Neural Network Capabilities\n",
        "print(\"Testing TensorFlow/Keras neural network creation and training...\")\n",
        "\n",
        "# Create a sample neural network (similar to what PPO will use internally)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "    keras.layers.Dropout(0.2),  # Add dropout for better generalization\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "], name=\"EscapeCageTestNetwork\")\n",
        "\n",
        "# Compile with optimizer similar to PPO\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy', \n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")\n",
        "\n",
        "print(f\"Neural network '{model.name}' created successfully\")\n",
        "print(f\"   Total parameters: {model.count_params():,}\")\n",
        "print(f\"   Layers: {len(model.layers)}\")\n",
        "\n",
        "# Generate synthetic training data (simulating environment observations)\n",
        "print(\"\\nTesting training loop with synthetic data...\")\n",
        "X_train = np.random.random((1000, 10))  # Simulate observations\n",
        "y_train = np.random.randint(0, 2, 1000)  # Simulate binary decisions\n",
        "\n",
        "X_test = np.random.random((200, 10))\n",
        "y_test = np.random.randint(0, 2, 200)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    verbose=0  # Silent training\n",
        ")\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss, test_acc, test_prec, test_recall = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Training completed successfully!\")\n",
        "print(f\"   Final accuracy: {test_acc:.3f}\")\n",
        "print(f\"   Final loss: {test_loss:.3f}\")\n",
        "print(f\"   Precision: {test_prec:.3f}\")\n",
        "print(f\"   Recall: {test_recall:.3f}\")\n",
        "\n",
        "# Test prediction\n",
        "sample_prediction = model.predict(X_test[:1], verbose=0)\n",
        "print(f\"   Sample prediction: {sample_prediction[0][0]:.3f}\")\n",
        "\n",
        "print(\"\\nTensorFlow/Keras functionality verified!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ® Testing RL environment...\n",
            "Environment: CartPole-v1\n",
            "Observation space: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
            "Action space: Discrete(2)\n",
            "âœ… PPO agent created successfully\n",
            "âœ… RL libraries test successful!\n",
            "\n",
            "ðŸŽ‰ ALL TESTS PASSED! Environment is ready for Escape Cage RL project!\n"
          ]
        }
      ],
      "source": [
        "# Testing Gymnasium and Stable-Baselines3 RL Framework\n",
        "print(\"Testing reinforcement learning environment and training framework...\")\n",
        "\n",
        "# Create and test a simple RL environment\n",
        "env = gym.make('CartPole-v1', render_mode=None)\n",
        "observation, info = env.reset()\n",
        "\n",
        "print(f\"Test Environment: {env.spec.id}\")\n",
        "print(f\"Observation space: {env.observation_space}\")\n",
        "print(f\"   Shape: {env.observation_space.shape}\")\n",
        "print(f\"   Data type: {env.observation_space.dtype}\")\n",
        "print(f\"Action space: {env.action_space}\")\n",
        "print(f\"   Actions available: {env.action_space.n}\")\n",
        "\n",
        "# Test environment interaction\n",
        "print(f\"\\nTesting environment interaction...\")\n",
        "total_reward = 0\n",
        "steps = 0\n",
        "\n",
        "for step in range(50):  # Run for 50 steps\n",
        "    action = env.action_space.sample()  # Random action\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    total_reward += reward\n",
        "    steps += 1\n",
        "    \n",
        "    if terminated or truncated:\n",
        "        break\n",
        "\n",
        "print(f\"   Environment interaction successful\")\n",
        "print(f\"   Steps taken: {steps}\")\n",
        "print(f\"   Total reward: {total_reward}\")\n",
        "\n",
        "# Test Stable-Baselines3 PPO Agent\n",
        "print(f\"\\nTesting PPO agent creation and training...\")\n",
        "\n",
        "# Create vectorized environment for PPO\n",
        "env_vec = make_vec_env('CartPole-v1', n_envs=1)\n",
        "\n",
        "# Create PPO agent with custom hyperparameters\n",
        "ppo_agent = PPO(\n",
        "    'MlpPolicy', \n",
        "    env_vec, \n",
        "    learning_rate=0.0003,\n",
        "    n_steps=2048,\n",
        "    batch_size=64,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(f\"PPO agent created successfully\")\n",
        "print(f\"   Policy type: MLP (Multi-Layer Perceptron)\")\n",
        "print(f\"   Learning rate: {ppo_agent.learning_rate}\")\n",
        "print(f\"   Batch size: {ppo_agent.batch_size}\")\n",
        "\n",
        "# Quick training test (minimal timesteps for speed)\n",
        "print(f\"\\nRunning quick training test...\")\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "ppo_agent.learn(total_timesteps=2000, progress_bar=False)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "# Test trained agent performance\n",
        "print(f\"\\nTesting trained agent performance...\")\n",
        "test_env = gym.make('CartPole-v1', render_mode=None)\n",
        "obs, _ = test_env.reset()\n",
        "\n",
        "test_reward = 0\n",
        "test_steps = 0\n",
        "\n",
        "for _ in range(200):  # Max steps for CartPole\n",
        "    action, _ = ppo_agent.predict(obs, deterministic=True)\n",
        "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
        "    test_reward += reward\n",
        "    test_steps += 1\n",
        "    \n",
        "    if terminated or truncated:\n",
        "        break\n",
        "\n",
        "print(f\"   Test episode reward: {test_reward}\")\n",
        "print(f\"   Test episode length: {test_steps}\")\n",
        "\n",
        "# Clean up\n",
        "env.close()\n",
        "env_vec.close()\n",
        "test_env.close()\n",
        "\n",
        "print(f\"\\nReinforcement Learning framework fully functional!\")\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ALL TESTS PASSED! Environment is ready for Escape Cage RL project!\")\n",
        "print(\"=\"*60)\n",
        "print(\"Summary:\")\n",
        "print(\"   TensorFlow/Keras: Neural networks working\")\n",
        "print(\"   Gymnasium: RL environments functional\") \n",
        "print(\"   Stable-Baselines3: PPO agent training successful\")\n",
        "print(\"   Full pipeline: Ready for escape cage training\")\n",
        "print(\"\\nYou can now proceed with training your escape cage AI!\")\n",
        "print(\"Next steps: Run the main training scripts in ml_training/\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "escape_cage_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
